{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandermurphy/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from plots import plot_train_compare2, plot_train_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hp_args_from_txt(path):\n",
    "    with open(path) as f:\n",
    "        data_string = f.read()\n",
    "\n",
    "        # Step 2: Define regex patterns to extract the values\n",
    "        poison_lr_pattern = r\"'poison_lr'\\s*:\\s*([0-9.]+)\"\n",
    "        iterations_pattern = r\"'iterations'\\s*:\\s*(\\d+)\"\n",
    "        epsilon_pattern = r\"'epsilon'\\s*:\\s*([0-9.]+)\"\n",
    "        poison_start_epoch_pattern = r\"'poison_start_epoch'\\s*:\\s*(\\d+)\"\n",
    "\n",
    "        # Step 3: Extract the values using regex\n",
    "        poison_lr = re.search(poison_lr_pattern, data_string).group(1)\n",
    "        iterations = re.search(iterations_pattern, data_string).group(1)\n",
    "        epsilon = re.search(epsilon_pattern, data_string).group(1)\n",
    "        poison_start_epoch = re.search(poison_start_epoch_pattern, data_string).group(1)\n",
    "\n",
    "        # Print the extracted values\n",
    "        return (poison_lr, iterations, epsilon, poison_start_epoch)\n",
    "\n",
    "def get_tests_vals_from_txt(path, one_run):\n",
    "    vals = []\n",
    "    tests = []\n",
    "    vals_p = []\n",
    "    tests_p = []\n",
    "    with open(path) as f:\n",
    "        highest_val = -1\n",
    "        highest_val_p = -1\n",
    "        highest_test = -1\n",
    "        highest_test_p = -1\n",
    "        i = 0\n",
    "        for l in f.readlines():\n",
    "            i += 1\n",
    "            val_acc = float(re.findall(r\"Val_accuracy:(\\d+\\.\\d+)\", l)[0])\n",
    "            test_acc = float(re.findall(r\"Test_accuracy:(\\d+\\.\\d+)\", l)[0])\n",
    "            if i >= 200:\n",
    "                break\n",
    "            elif i >= 100 and not one_run:\n",
    "                if val_acc > highest_val_p:\n",
    "                    highest_val_p = val_acc\n",
    "                    highest_test_p = test_acc\n",
    "                vals_p.append(val_acc)\n",
    "                tests_p.append(test_acc)\n",
    "            elif i < 100 or one_run:\n",
    "                if val_acc > highest_val:\n",
    "                    highest_val = val_acc\n",
    "                    highest_test = test_acc\n",
    "                vals.append(val_acc)\n",
    "                tests.append(test_acc)\n",
    "    return (vals, vals_p, highest_val, highest_val_p, tests, tests_p, highest_test, highest_test_p)\n",
    "    \n",
    "def construct_run_dicts(base_path, one_run=False):\n",
    "    ids = next(os.walk(base_path))[1]\n",
    "    runs = {}\n",
    "    for id in ids:\n",
    "        d = {}\n",
    "        path = f\"{base_path}/{id}/metrics.txt\"\n",
    "        vals, vals_p, highest_val, highest_val_p, tests, tests_p, highest_test, highest_test_p = get_tests_vals_from_txt(path, one_run)\n",
    "        \n",
    "        d[\"vals\"] = vals\n",
    "        d[\"vals_p\"] = vals_p\n",
    "        d[\"highest_val\"] = highest_val\n",
    "        d[\"highest_val_p\"] = highest_val_p\n",
    "        \n",
    "        d[\"tests\"] = tests\n",
    "        d[\"tests_p\"] = tests_p\n",
    "        d[\"highest_test\"] = highest_test\n",
    "        d[\"highest_test_p\"] = highest_test_p\n",
    "\n",
    "        d[\"ratio\"] = d[\"highest_val_p\"]/d[\"highest_val\"]\n",
    "\n",
    "        runs[id] = d\n",
    "    return runs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FMNIST RESNET18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM mean test: 91.98999999999998 +- 0.16451950239004176\n",
      "Poison mean test: 91.99333333333333 +- 0.15003703246569375\n",
      "Baseline mean test: 91.64333333333335 +- 0.44629337635436456\n"
     ]
    }
   ],
   "source": [
    "runs_poison = construct_run_dicts('experiment_results_from_eddie/fmnist_res_net_18/poison_final')\n",
    "runs_baseline = construct_run_dicts('experiment_results_from_eddie/fmnist_res_net_18/baseline_final')\n",
    "\n",
    "highest_tests_sam_list = [runs_poison[d][\"highest_test\"] for d in runs_poison]\n",
    "highest_tests_p_list = [runs_poison[d][\"highest_test_p\"] for d in runs_poison]\n",
    "highest_tests_baseline_list = [runs_baseline[d][\"highest_test\"] for d in runs_baseline]\n",
    "\n",
    "print(\"SAM mean test:\", np.mean(highest_tests_sam_list), \"+-\", np.std(highest_tests_sam_list))\n",
    "print(\"Poison mean test:\", np.mean(highest_tests_p_list), \"+-\", np.std(highest_tests_p_list))\n",
    "print(\"Baseline mean test:\", np.mean(highest_tests_baseline_list), \"+-\", np.std(highest_tests_baseline_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR100 WIDE16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM mean test: 67.27333333333334 +- 0.4644710252893417\n",
      "Poison mean test: 70.12666666666668 +- 0.41547830535687447\n",
      "Baseline mean test: 70.07666666666667 +- 0.22226110770892657\n"
     ]
    }
   ],
   "source": [
    "runs_poison = construct_run_dicts('experiment_results_from_eddie/cifar100_wide16/poison/train_w_poison', one_run=True)\n",
    "runs_deltas = construct_run_dicts('experiment_results_from_eddie/cifar100_wide16/poison/deltas', one_run=True)\n",
    "runs_baseline = construct_run_dicts('experiment_results_from_eddie/cifar100_wide16/baseline', one_run=True)\n",
    "\n",
    "highest_tests_sam_list = [runs_deltas[d][\"highest_test\"] for d in runs_deltas]\n",
    "highest_tests_p_list = [runs_poison[d][\"highest_test\"] for d in runs_poison]\n",
    "highest_tests_baseline_list = [runs_baseline[d][\"highest_test\"] for d in runs_baseline]\n",
    "\n",
    "print(\"SAM mean test:\", np.mean(highest_tests_sam_list), \"+-\", np.std(highest_tests_sam_list))\n",
    "print(\"Poison mean test:\", np.mean(highest_tests_p_list), \"+-\", np.std(highest_tests_p_list))\n",
    "print(\"Baseline mean test:\", np.mean(highest_tests_baseline_list), \"+-\", np.std(highest_tests_baseline_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 WIDE16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM mean test: 90.01333333333334 +- 0.25460208605237505\n",
      "Poison mean test: 91.16 +- 0.23537204591879696\n",
      "Baseline mean test: 91.78333333333333 +- 0.4079760341545086\n"
     ]
    }
   ],
   "source": [
    "runs_poison = construct_run_dicts('experiment_results_from_eddie/cifar10_wide16/poison/train_w_poison', one_run=True)\n",
    "runs_deltas = construct_run_dicts('experiment_results_from_eddie/cifar10_wide16/poison/deltas', one_run=True)\n",
    "runs_baseline = construct_run_dicts('experiment_results_from_eddie/cifar10_wide16/baseline', one_run=True)\n",
    "\n",
    "highest_tests_sam_list = [runs_deltas[d][\"highest_test\"] for d in runs_deltas]\n",
    "highest_tests_p_list = [runs_poison[d][\"highest_test\"] for d in runs_poison]\n",
    "highest_tests_baseline_list = [runs_baseline[d][\"highest_test\"] for d in runs_baseline]\n",
    "\n",
    "print(\"SAM mean test:\", np.mean(highest_tests_sam_list), \"+-\", np.std(highest_tests_sam_list))\n",
    "print(\"Poison mean test:\", np.mean(highest_tests_p_list), \"+-\", np.std(highest_tests_p_list))\n",
    "print(\"Baseline mean test:\", np.mean(highest_tests_baseline_list), \"+-\", np.std(highest_tests_baseline_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_poison = construct_run_dicts('experiment_results_from_eddie/cifar10_wide16/poison/train_w_poison', one_run=True)\n",
    "runs_deltas = construct_run_dicts('experiment_results_from_eddie/cifar10_wide16/poison/deltas', one_run=True)\n",
    "runs_baseline = construct_run_dicts('experiment_results_from_eddie/cifar10_wide16/baseline', one_run=True)\n",
    "\n",
    "highest_tests_sam_list = [runs_deltas[d][\"highest_test\"] for d in runs_deltas]\n",
    "highest_tests_p_list = [runs_poison[d][\"highest_test\"] for d in runs_poison]\n",
    "highest_tests_baseline_list = [runs_baseline[d][\"highest_test\"] for d in runs_baseline]\n",
    "\n",
    "print(\"SAM mean test:\", np.mean(highest_tests_sam_list), \"+-\", np.std(highest_tests_sam_list))\n",
    "print(\"Poison mean test:\", np.mean(highest_tests_p_list), \"+-\", np.std(highest_tests_p_list))\n",
    "print(\"Baseline mean test:\", np.mean(highest_tests_baseline_list), \"+-\", np.std(highest_tests_baseline_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
